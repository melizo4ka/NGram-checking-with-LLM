{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f7c5d-46f3-4cbd-80ad-f1e50cd65096",
   "metadata": {
    "tags": []
   },
   "source": [
    "# N-grams as Tokens for Phrases\n",
    "\n",
    "In this first project work we will use N-grams as tokens to create phrases in English and evaluate how much sense these phrases make.\n",
    "\n",
    "If executing then need to set n as the N-gram length, all_words as words of the dictionary, load the model of corresponding name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2b6d1-3df0-464c-9a5f-8c611257a971",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "We will use an existing corpus called NLTK library and create a dictionary of bi-grams, tri-grams, and four-grams out of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de291f3f-79f7-4a34-aca7-8f9b023a60f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install numpy==1.19.5 matplotlib==3.3.4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2fb256-f8c3-47bf-ae7c-eed42ab0f182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install transformers torch sentencepiece torcheval happytransformer evaluate rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e0236-2f8b-45f9-bd62-b59729a5cd1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "from nltk.corpus import brown, gutenberg\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f21272-92d6-4b12-9805-81e18c6c552a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# punkt is a Sentence Tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f09294-a479-4d32-af35-c235ddbf95e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the corpus\n",
    "all_words = brown.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b6df7-e1fc-43b5-9e9b-44f3027b7e8e",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "We want to create an N-gram language model using the data prepared in the first step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf21208-3bb9-429f-853a-1f1bf8908ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigram_model(trigrams):\n",
    "    # getting the frequency of each n-gram\n",
    "    ngram_freq = Counter(trigrams)\n",
    "\n",
    "    # creating a dictionary where each (n-1)-gram maps to possible next words\n",
    "    model = defaultdict(list)\n",
    "\n",
    "    # for trigrams, the prefix will be the first two words, and the next word will be the third\n",
    "    for (w1, w2, w3) in trigrams:\n",
    "        model[(w1, w2)].append(w3)\n",
    "\n",
    "    return ngram_freq, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1448a7d-54be-4ab1-8a99-87d509da8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigram_model(bigrams):\n",
    "    ngram_freq = Counter(bigrams)\n",
    "\n",
    "    model = defaultdict(list)\n",
    "\n",
    "    for (w1, w2) in bigrams:\n",
    "        model[w1].append(w2)\n",
    "\n",
    "    return ngram_freq, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bdea2-c99f-4a55-9f5c-4a9c86077506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fourgram_model(fourgrams):\n",
    "    ngram_freq = Counter(fourgrams)\n",
    "\n",
    "    model = defaultdict(list)\n",
    "\n",
    "    for (w1, w2, w3, w4) in fourgrams:\n",
    "        model[(w1, w2, w3)].append(w4)\n",
    "\n",
    "    return ngram_freq, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb8fb3-5bfe-485d-b41d-b49492fb2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating model\n",
    "n = 3\n",
    "trigrams = list(ngrams(all_words, n))\n",
    "\n",
    "ngram_freq, model_ngram = create_trigram_model(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadc239-5892-4497-8d2f-705a58dfc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating model\n",
    "n = 3\n",
    "bigrams = list(ngrams(all_words, n))\n",
    "\n",
    "ngram_freq, model_ngram = create_bigram_model(bigrams)\n",
    "\n",
    "with open('br_bi_model.pkl', 'wb') as f:\n",
    "    pickle.dump((ngram_freq, model_ngram), f)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999faf4-0b6f-4273-b564-f6dfbce302c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('br_four_model.pkl', 'rb') as f:\n",
    "    ngram_freq, model_ngram = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31e941-30ae-41c1-b7af-dcdfca168387",
   "metadata": {},
   "source": [
    "### Generating phrases\n",
    "We will create a phrase one word at a time based on the frequency of the N-grams in our dictionary until a phrase is of a certain length or a stop condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a7171b-320a-4752-8373-e35426f0e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_text(model, start_words, n, length=50):\n",
    "    text = list(start_words)\n",
    "    \n",
    "    if n==2:\n",
    "        current_words = start_words[-1]\n",
    "    else:\n",
    "        current_words = tuple(start_words)\n",
    "        \n",
    "    for _ in range(length):\n",
    "        if current_words in model and model[current_words]:\n",
    "            possible_words = model[current_words]\n",
    "            next_word = random.choice(possible_words)\n",
    "            \n",
    "            if len(set(possible_words)) > 1:\n",
    "                while next_word == text[-1]:\n",
    "                    next_word = random.choice(possible_words)\n",
    "            else:\n",
    "                # use the only possible option\n",
    "                next_word = possible_words[0]\n",
    "\n",
    "            if next_word in {'``', \"''\", \"--\"}:\n",
    "                continue\n",
    "            \n",
    "            # Check if the next word is punctuation, then break before appending\n",
    "            if next_word in {\".\", \"!\", \"?\"}:\n",
    "                text.append(next_word)\n",
    "                break\n",
    "                \n",
    "            text.append(next_word)\n",
    "            \n",
    "            if n==2:\n",
    "                current_word = next_word\n",
    "            else:\n",
    "                current_words = tuple(text[-(len(start_words)):])\n",
    "        else:\n",
    "            break  # Stop if we no next word is available\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801726d7-d14f-41e7-857b-3c2c32a80342",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "\n",
    "if n==2:\n",
    "    start_words = ('In',)\n",
    "elif n==3:\n",
    "    start_words = ('In', 'a')\n",
    "elif n==4:\n",
    "    start_words = ('In', 'a', 'way')\n",
    "generated_random_text = generate_random_text(model_ngram, start_words, n)\n",
    "print(generated_random_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec319af-a72d-419e-a2fb-7ac56e8d8ab7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating phrases\n",
    "After generating a phrase we pass it to a LLM to evaluate its coherence and fluency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a424a1-5f2c-49db-9c7a-19b6ac9b087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "from torcheval.metrics.text import Perplexity\n",
    "import evaluate\n",
    "\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3761492-1a04-420f-aa7a-bfce0313550d",
   "metadata": {},
   "source": [
    "Using **HappyTextToText** to check and correct the phrase's grammar produced by the N-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce31c8da-2c4c-4ced-8c5f-25237325d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from happytransformer import HappyTextToText, TTSettings\n",
    "happy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1c1305-54ff-4f53-86f2-021206cd953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(input_phrase):\n",
    "    args = TTSettings(num_beams=5, min_length=1,  max_length=60)\n",
    "\n",
    "    formatted_input = f\"grammar: {input_phrase}\"\n",
    "    result = happy_tt.generate_text(formatted_input, args=args)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac2fba-58fe-4048-8f23-2025d735369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated_random_text)\n",
    "corrected_result = correct_grammar(generated_random_text)\n",
    "print(corrected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddcb16-38f0-4ed1-9063-9545cae21b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "model.to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca526b-606e-4635-a1f1-907780807fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phrase_likelihood(phrase):\n",
    "    input_ids = tokenizer(phrase, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "    \n",
    "    return -loss.item()\n",
    "\n",
    "likelihood_score_initial = compute_phrase_likelihood(generated_random_text)\n",
    "print(\"Initial Phrase:\", generated_random_text)\n",
    "print(\"Likelihood Score at the start:\", likelihood_score_initial)\n",
    "\n",
    "likelihood_score_corrected = compute_phrase_likelihood(corrected_result)\n",
    "print(\"Corrected Phrase:\", corrected_result)\n",
    "print(\"Likelihood Score:\", likelihood_score_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6283547-edcd-493c-ad9c-0b691620707f",
   "metadata": {},
   "source": [
    "Other metrics to evaluate phrases can be:\n",
    "- BLEU \n",
    "- ROUGE\n",
    "\n",
    "Both of them need the same number of sentences in references and predictions, so we compare the sentence produced by our N-gram model and the one produced by HappyTextToText to see how close they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99f728-2396-41d2-b8a0-d4487002212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [generated_random_text]\n",
    "references = [[corrected_result]]\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "results_bleu = bleu.compute(predictions=predictions, references=references)\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "results_rouge = rouge.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973adad-9cbd-4ca3-9eee-033e6cee4a2a",
   "metadata": {},
   "source": [
    "This next part is used to test how well does the model perform in regards to the metrics implemented. It is also interesting to see how long the produced phrases are. We will print phrases that have particularly bad BLEU score to understand the reason for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58da1ae-a92f-471c-be3a-e0e57357167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2be95c-e7ff-4102-8c4c-2655accfcf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_start_words(all_words, i):\n",
    "    while True:\n",
    "        index = random.randint(0, len(all_words) - i)\n",
    "        if all_words[index][0].isalpha():\n",
    "            if i==1:\n",
    "                start_words = (all_words[index],)\n",
    "            if i==2:\n",
    "                start_words = (all_words[index], all_words[index + 1])\n",
    "            if i==3:\n",
    "                start_words = (all_words[index], all_words[index + 1], all_words[index + 2])\n",
    "            return start_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b12b40-dcc6-4327-855d-207d7d958221",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b758d50f-192e-4134-aa36-b41023ffee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = gutenberg.words()\n",
    "n=4\n",
    "with open('gut_four_model.pkl', 'rb') as f:\n",
    "    ngram_freq, model_ngram = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b290ff-d851-4570-b50c-f95877528596",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_print = False\n",
    "# testing length of generated phrases and BLEU and ROUGE values\n",
    "X = 200\n",
    "lengths_of_phrases = []\n",
    "lengths_of_phrases_to_score = []\n",
    "\n",
    "to_see = 0\n",
    "\n",
    "bleu_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "for i in range(X):\n",
    "    # to generate at random the starting words of the given dictionary\n",
    "    start_words = generate_start_words(all_words, n-1)\n",
    "\n",
    "    generated_random_text = generate_random_text(model_ngram, start_words, n)\n",
    "    lengths_of_phrases.append(len(generated_random_text.split()))\n",
    "    \n",
    "    if 10 <= len(generated_random_text.split()) <= 50:\n",
    "        lengths_of_phrases_to_score.append(len(generated_random_text.split()))\n",
    "        \n",
    "        corrected_result = correct_grammar(generated_random_text)\n",
    "\n",
    "        predictions = [generated_random_text]\n",
    "        references = [[corrected_result]]\n",
    "\n",
    "        results_bleu = bleu.compute(predictions=predictions, references=references)\n",
    "        bleu_score = results_bleu['bleu']\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "        results_rouge = rouge.compute(predictions=predictions, references=references)\n",
    "        rougeL_score = results_rouge['rougeL']\n",
    "        rougeL_scores.append(rougeL_score)\n",
    "\n",
    "        # to produce some examples we print 100 phrases with relative corrections\n",
    "        if to_see < 100:\n",
    "            to_see += 1\n",
    "            print(generated_random_text)\n",
    "            print(corrected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bddf8-b027-434a-a2dd-42de7ebc87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the generated phrase length\n",
    "\n",
    "length_counts = Counter(lengths_of_phrases)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(length_counts.keys(), length_counts.values(), color='skyblue')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Generated Sentence Lengths')\n",
    "plt.xticks(list(length_counts.keys()))\n",
    "plt.grid(axis='y')\n",
    "plt.yticks(range(0, max(length_counts.values()) + 1))\n",
    "\n",
    "plt.savefig('lengths.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad469a2d-8f35-4982-b758-f38e39013600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting BLEU and ROUGE\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(lengths_of_phrases_to_score, bleu_scores, color='blue', label='BLEU Score')\n",
    "plt.scatter(lengths_of_phrases_to_score, rougeL_scores, color='red', label='ROUGE-L Score')\n",
    "\n",
    "plt.xlabel('Phrase Length')\n",
    "plt.ylabel('Score')\n",
    "plt.title('BLEU and ROUGE-L Scores')\n",
    "plt.ylim(0, 1.1)  # Scores are between 0 and 1\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('scores.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71661b0-11cc-44c0-93da-2787b3cb0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score = np.mean(bleu_scores)\n",
    "print(\"Mean BLEU Score:\", mean_bleu_score)\n",
    "\n",
    "mean_rouge_score = np.mean(rougeL_scores)\n",
    "print(\"Mean ROUGE Score:\", mean_rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce7b4b-1773-4364-8f6c-cd547dc4f50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
