{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97f7c5d-46f3-4cbd-80ad-f1e50cd65096",
   "metadata": {
    "tags": []
   },
   "source": [
    "# N-grams as Tokens for Phrases\n",
    "\n",
    "In this first project work we will use N-grams as tokens to create phrases in English and evaluate how much sense these phrases make.\n",
    "\n",
    "If executing then need to set n as the N-gram length, all_words as words of the dictionary, load the model of corresponding name."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb2b6d1-3df0-464c-9a5f-8c611257a971",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data preparation\n",
    "\n",
    "We will use an existing corpus called NLTK library and create a dictionary of bi-grams, tri-grams, and four-grams out of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de291f3f-79f7-4a34-aca7-8f9b023a60f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy==1.19.5 in c:\\users\\mo4al\\appdata\\roaming\\python\\python39\\site-packages (1.19.5)\n",
      "Requirement already satisfied: matplotlib==3.3.4 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (3.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from matplotlib==3.3.4) (1.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from matplotlib==3.3.4) (2.8.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from matplotlib==3.3.4) (9.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from matplotlib==3.3.4) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from matplotlib==3.3.4) (0.11.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from python-dateutil>=2.1->matplotlib==3.3.4) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install numpy==1.19.5 matplotlib==3.3.4 --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce2fb256-f8c3-47bf-ae7c-eed42ab0f182",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (4.45.2)\n",
      "Requirement already satisfied: torch in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: torcheval in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (0.0.7)\n",
      "Requirement already satisfied: happytransformer in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: evaluate in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (0.4.3)\n",
      "Requirement already satisfied: rouge-score in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (0.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\mo4al\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (0.20.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from torch) (2.11.3)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from torch) (1.10.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from torch) (2.7.1)\n",
      "Requirement already satisfied: datasets<3.0.0,>=2.13.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from happytransformer) (2.21.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from happytransformer) (3.19.1)\n",
      "Requirement already satisfied: wandb in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from happytransformer) (0.18.5)\n",
      "Requirement already satisfied: accelerate<1.0.0,>=0.20.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from happytransformer) (0.34.2)\n",
      "Requirement already satisfied: multiprocess in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from evaluate) (0.70.16)\n",
      "Requirement already satisfied: xxhash in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from evaluate) (3.5.0)\n",
      "Requirement already satisfied: dill in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from evaluate) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from evaluate) (1.4.2)\n",
      "Requirement already satisfied: six>=1.14.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from rouge-score) (1.16.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from rouge-score) (3.7)\n",
      "Requirement already satisfied: absl-py in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from rouge-score) (2.1.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from accelerate<1.0.0,>=0.20.1->happytransformer) (5.8.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (17.0.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from datasets<3.0.0,>=2.13.1->happytransformer) (3.8.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.6.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (5.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (4.0.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.2.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from aiohttp->datasets<3.0.0,>=2.13.1->happytransformer) (2.0.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.16)\n",
      "Requirement already satisfied: colorama in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.0.1)\n",
      "Requirement already satisfied: click in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (8.0.4)\n",
      "Requirement already satisfied: joblib in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from nltk->rouge-score) (1.1.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from pandas->evaluate) (2.8.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from sympy->torch) (1.2.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from wandb->happytransformer) (61.2.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from wandb->happytransformer) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from wandb->happytransformer) (4.3.6)\n",
      "Requirement already satisfied: setproctitle in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from wandb->happytransformer) (1.3.3)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from wandb->happytransformer) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from wandb->happytransformer) (2.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (4.0.11)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\mo4al\\anaconda3\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->happytransformer) (5.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers torch sentencepiece torcheval happytransformer evaluate rouge-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957e0236-2f8b-45f9-bd62-b59729a5cd1b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "from nltk.util import ngrams\n",
    "import nltk\n",
    "from nltk.corpus import brown, gutenberg\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5f21272-92d6-4b12-9805-81e18c6c552a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\mo4al\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package gutenberg to\n",
      "[nltk_data]     C:\\Users\\mo4al\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package gutenberg is already up-to-date!\n",
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\mo4al\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# punkt is a Sentence Tokenizer\n",
    "nltk.download('punkt')\n",
    "\n",
    "nltk.download('gutenberg')\n",
    "nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f09294-a479-4d32-af35-c235ddbf95e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# loading the corpus\n",
    "all_words = brown.words()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3b6df7-e1fc-43b5-9e9b-44f3027b7e8e",
   "metadata": {},
   "source": [
    "### Building the model\n",
    "We want to create an N-gram language model using the data prepared in the first step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf21208-3bb9-429f-853a-1f1bf8908ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trigram_model(trigrams):\n",
    "    # getting the frequency of each n-gram\n",
    "    ngram_freq = Counter(trigrams)\n",
    "\n",
    "    # creating a dictionary where each (n-1)-gram maps to possible next words\n",
    "    model = defaultdict(list)\n",
    "\n",
    "    # for trigrams, the prefix will be the first two words, and the next word will be the third\n",
    "    for (w1, w2, w3) in trigrams:\n",
    "        model[(w1, w2)].append(w3)\n",
    "\n",
    "    return ngram_freq, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1448a7d-54be-4ab1-8a99-87d509da8714",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bigram_model(bigrams):\n",
    "    ngram_freq = Counter(bigrams)\n",
    "\n",
    "    model = defaultdict(list)\n",
    "\n",
    "    for (w1, w2) in bigrams:\n",
    "        model[w1].append(w2)\n",
    "\n",
    "    return ngram_freq, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2bdea2-c99f-4a55-9f5c-4a9c86077506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fourgram_model(fourgrams):\n",
    "    ngram_freq = Counter(fourgrams)\n",
    "\n",
    "    model = defaultdict(list)\n",
    "\n",
    "    for (w1, w2, w3, w4) in fourgrams:\n",
    "        model[(w1, w2, w3)].append(w4)\n",
    "\n",
    "    return ngram_freq, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb8fb3-5bfe-485d-b41d-b49492fb2c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating model\n",
    "n = 3\n",
    "trigrams = list(ngrams(all_words, n))\n",
    "\n",
    "ngram_freq, model_ngram = create_trigram_model(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eadc239-5892-4497-8d2f-705a58dfc73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating model\n",
    "n = 3\n",
    "bigrams = list(ngrams(all_words, n))\n",
    "\n",
    "ngram_freq, model_ngram = create_bigram_model(bigrams)\n",
    "\n",
    "with open('br_bi_model.pkl', 'wb') as f:\n",
    "    pickle.dump((ngram_freq, model_ngram), f)\n",
    "\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c999faf4-0b6f-4273-b564-f6dfbce302c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('br_four_model.pkl', 'rb') as f:\n",
    "    ngram_freq, model_ngram = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d31e941-30ae-41c1-b7af-dcdfca168387",
   "metadata": {},
   "source": [
    "### Generating phrases\n",
    "We will create a phrase one word at a time based on the frequency of the N-grams in our dictionary until a phrase is of a certain length or a stop condition is met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7a7171b-320a-4752-8373-e35426f0e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_text(model, start_words, n, length=50):\n",
    "    text = list(start_words)\n",
    "    \n",
    "    if n==2:\n",
    "        current_words = start_words[-1]\n",
    "    else:\n",
    "        current_words = tuple(start_words)\n",
    "        \n",
    "    for _ in range(length):\n",
    "        if current_words in model and model[current_words]:\n",
    "            possible_words = model[current_words]\n",
    "            next_word = random.choice(possible_words)\n",
    "            \n",
    "            if len(set(possible_words)) > 1:\n",
    "                while next_word == text[-1]:\n",
    "                    next_word = random.choice(possible_words)\n",
    "            else:\n",
    "                # use the only possible option\n",
    "                next_word = possible_words[0]\n",
    "\n",
    "            if next_word in {'``', \"''\", \"--\"}:\n",
    "                continue\n",
    "            \n",
    "            # Check if the next word is punctuation, then break before appending\n",
    "            if next_word in {\".\", \"!\", \"?\"}:\n",
    "                text.append(next_word)\n",
    "                break\n",
    "                \n",
    "            text.append(next_word)\n",
    "            \n",
    "            if n==2:\n",
    "                current_word = next_word\n",
    "            else:\n",
    "                current_words = tuple(text[-(len(start_words)):])\n",
    "        else:\n",
    "            break  # Stop if we no next word is available\n",
    "    \n",
    "    return ' '.join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801726d7-d14f-41e7-857b-3c2c32a80342",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=4\n",
    "\n",
    "if n==2:\n",
    "    start_words = ('In',)\n",
    "elif n==3:\n",
    "    start_words = ('In', 'a')\n",
    "elif n==4:\n",
    "    start_words = ('In', 'a', 'way')\n",
    "generated_random_text = generate_random_text(model_ngram, start_words, n)\n",
    "print(generated_random_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ec319af-a72d-419e-a2fb-7ac56e8d8ab7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Evaluating phrases\n",
    "After generating a phrase we pass it to a LLM to evaluate its coherence and fluency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37a424a1-5f2c-49db-9c7a-19b6ac9b087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import sentencepiece as spm\n",
    "from torcheval.metrics.text import Perplexity\n",
    "import evaluate\n",
    "\n",
    "torch_device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3761492-1a04-420f-aa7a-bfce0313550d",
   "metadata": {},
   "source": [
    "Using **HappyTextToText** to check and correct the phrase's grammar produced by the N-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce31c8da-2c4c-4ced-8c5f-25237325d86b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12/08/2024 18:11:05 - INFO - happytransformer.happy_transformer -   Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "from happytransformer import HappyTextToText, TTSettings\n",
    "happy_tt = HappyTextToText(\"T5\", \"vennify/t5-base-grammar-correction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a1c1305-54ff-4f53-86f2-021206cd953b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_grammar(input_phrase):\n",
    "    args = TTSettings(num_beams=5, min_length=1,  max_length=60)\n",
    "\n",
    "    formatted_input = f\"grammar: {input_phrase}\"\n",
    "    result = happy_tt.generate_text(formatted_input, args=args)\n",
    "    \n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ac2fba-58fe-4048-8f23-2025d735369c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated_random_text)\n",
    "corrected_result = correct_grammar(generated_random_text)\n",
    "print(corrected_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ddcb16-38f0-4ed1-9063-9545cae21b7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "tokenizer = T5Tokenizer.from_pretrained('t5-base')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-base')\n",
    "model.to(torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca526b-606e-4635-a1f1-907780807fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_phrase_likelihood(phrase):\n",
    "    input_ids = tokenizer(phrase, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids, labels=input_ids)\n",
    "        loss = outputs.loss\n",
    "    \n",
    "    return -loss.item()\n",
    "\n",
    "likelihood_score_initial = compute_phrase_likelihood(generated_random_text)\n",
    "print(\"Initial Phrase:\", generated_random_text)\n",
    "print(\"Likelihood Score at the start:\", likelihood_score_initial)\n",
    "\n",
    "likelihood_score_corrected = compute_phrase_likelihood(corrected_result)\n",
    "print(\"Corrected Phrase:\", corrected_result)\n",
    "print(\"Likelihood Score:\", likelihood_score_corrected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6283547-edcd-493c-ad9c-0b691620707f",
   "metadata": {},
   "source": [
    "Other metrics to evaluate phrases can be:\n",
    "- BLEU \n",
    "- ROUGE\n",
    "\n",
    "Both of them need the same number of sentences in references and predictions, so we compare the sentence produced by our N-gram model and the one produced by HappyTextToText to see how close they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d99f728-2396-41d2-b8a0-d4487002212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [generated_random_text]\n",
    "references = [[corrected_result]]\n",
    "\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "results_bleu = bleu.compute(predictions=predictions, references=references)\n",
    "\n",
    "rouge = evaluate.load('rouge')\n",
    "results_rouge = rouge.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a973adad-9cbd-4ca3-9eee-033e6cee4a2a",
   "metadata": {},
   "source": [
    "### Testing\n",
    "This next part is used to test how well does the model perform in regards to the metrics implemented. It is also interesting to see how long the produced phrases are. We will print phrases that have particularly bad BLEU score to understand the reason for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f58da1ae-a92f-471c-be3a-e0e57357167b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db2be95c-e7ff-4102-8c4c-2655accfcf39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_start_words(all_words, i):\n",
    "    while True:\n",
    "        index = random.randint(0, len(all_words) - i)\n",
    "        if all_words[index][0].isalpha():\n",
    "            if i==1:\n",
    "                start_words = (all_words[index],)\n",
    "            if i==2:\n",
    "                start_words = (all_words[index], all_words[index + 1])\n",
    "            if i==3:\n",
    "                start_words = (all_words[index], all_words[index + 1], all_words[index + 2])\n",
    "            return start_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20b12b40-dcc6-4327-855d-207d7d958221",
   "metadata": {},
   "outputs": [],
   "source": [
    "bleu = evaluate.load(\"bleu\")\n",
    "rouge = evaluate.load('rouge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b758d50f-192e-4134-aa36-b41023ffee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "all_words = brown.words()\n",
    "n=4\n",
    "with open('br_four_model.pkl', 'rb') as f:\n",
    "    ngram_freq, model_ngram = pickle.load(f)\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18b290ff-d851-4570-b50c-f95877528596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on station , it may be said to repeat itself ; ; much of it as a unified whole extending from grade school to university .\n",
      "On station, it may be said to repeat itself ; ; much of it as a unified whole extending from grade school to university .\n",
      "BLEU is  0.9590965597935381\n",
      "ROUGE is  1.0\n",
      "be broad stairs in a long adagio passage that is of fantastic difficulty , as well as Thomas but he imagined a moving base with infantry wings instead of cavalry wings .\n",
      "There are broad stairs in a long adagio passage that is of fantastic difficulty, as well as Thomas, but he imagined a moving base with infantry wings instead of cavalry wings.\n",
      "BLEU is  0.8602302883775147\n",
      "ROUGE is  0.9508196721311476\n",
      "and taste of any white wine will die a lingering death when it is directed by a leading merchant in Strasbourg whom she had already revealed a trill almost unprecedented in years of performances of\n",
      "And taste of any white wine will die a lingering death when it is directed by a leading merchant in Strasbourg, whom she had already revealed a trill almost unprecedented in years of performances of white wines.\n",
      "BLEU is  0.8237409767743542\n",
      "ROUGE is  0.9722222222222222\n",
      "match , and at the same time upgrading quality .\n",
      "Match , and at the same time upgrading quality .\n",
      "BLEU is  0.8801117367933934\n",
      "ROUGE is  1.0\n",
      "its over-stitched raised pattern in blue , pink , bronze and gold and a sauterne background .\n",
      "Its over-stitched raised pattern in blue , pink , bronze and gold and a sauterne background.\n",
      "BLEU is  0.9351334836242398\n",
      "ROUGE is  1.0\n",
      "and , in Mann's version of this legend , prolonging its burial , when it well deserves a rest after the overexploitation of the past .\n",
      "And , in Mann's version of this legend , prolonging its burial , when it well deserves a rest after the overexploitation of the past .\n",
      "BLEU is  0.9590965597935381\n",
      "ROUGE is  1.0\n",
      "She greeted her husband's colleagues with smiling politeness , offering nothing .\n",
      "She greeted her husband's colleagues with smiling politeness, offering nothing.\n",
      "BLEU is  1.0\n",
      "ROUGE is  1.0\n",
      "Worms , which I did not even know what sort of clothes I ought to leave that , seeing he won't take my clotheshorse\n",
      "Worms , which I did not even know what sort of clothes I ought to leave that , seeing he won't take my clotheshorse.\n",
      "BLEU is  0.9591894571091382\n",
      "ROUGE is  1.0\n",
      "giving them an answer , I'm confident , because he always felt that he merely belonged among the myriad citizens of our community who are mentally unhinged\n",
      "I'm confident in giving them an answer because he always felt that he merely belongs among the myriad citizens of our community who are mentally unhinged.\n",
      "BLEU is  0.697756759594737\n",
      "ROUGE is  0.830188679245283\n",
      "America in Congress assembled , That the Act of July 3 , 1952 ( 66 Stat. 328 ) as amended ( 42 U.S.C. 1952-1958 ) , is further amended to read : The authority of the Pope .\n",
      "America in Congress assembled , That the Act of July 3 , 1952 ( 66 Stat. 328 ) as amended ( 42 U.S.C. 1952-1958 ) is further amended to read : The authority of the Pope .\n",
      "BLEU is  0.9427781070492712\n",
      "ROUGE is  1.0\n",
      "rates of return , some probably much lower and some higher .\n",
      "Rates of return , some probably much lower and some higher.\n",
      "BLEU is  0.9036020036098448\n",
      "ROUGE is  1.0\n",
      "time . Finally , the conception of the man .\n",
      "Finally, the conception of the man.\n",
      "BLEU is  0.7598356856515925\n",
      "ROUGE is  0.923076923076923\n",
      "for instance , weep , whine or get hysterical .\n",
      "For instance, weep , whine or get hysterical.\n",
      "BLEU is  0.8801117367933934\n",
      "ROUGE is  1.0\n",
      "University . A third Thomas Bushell ( 1594-1674 ) ,\n",
      "University . A third Thomas Bushell (1594-1674 ) .\n",
      "BLEU is  0.9036020036098448\n",
      "ROUGE is  1.0\n",
      "I find the performance less exciting than New York Democrats may wish , it nevertheless must be made .\n",
      "I find the performance less exciting than New York Democrats may wish, but it nevertheless must be made.\n",
      "BLEU is  0.8606031405392816\n",
      "ROUGE is  0.9714285714285714\n",
      "the shopping district , the Spanish War , the American Library Association , and the anguish of the poor increase .\n",
      "The shopping district , the Spanish War , the American Library Association , and the anguish of the poor increase.\n",
      "BLEU is  0.948543837069451\n",
      "ROUGE is  1.0\n",
      "were found in three regions of the body was buried under the kitchen floor or as dots posted over period marks in used books .\n",
      "They were found in three regions of the body was buried under the kitchen floor or as dots posted over period marks in used books.\n",
      "BLEU is  0.9607894391523232\n",
      "ROUGE is  0.9795918367346939\n"
     ]
    }
   ],
   "source": [
    "to_print = False\n",
    "# testing length of generated phrases and BLEU and ROUGE values\n",
    "X = 30\n",
    "lengths_of_phrases = []\n",
    "lengths_of_phrases_to_score = []\n",
    "\n",
    "to_see = 0\n",
    "\n",
    "bleu_scores = []\n",
    "rougeL_scores = []\n",
    "\n",
    "for i in range(X):\n",
    "    # to generate at random the starting words of the given dictionary\n",
    "    start_words = generate_start_words(all_words, n-1)\n",
    "\n",
    "    generated_random_text = generate_random_text(model_ngram, start_words, n)\n",
    "    lengths_of_phrases.append(len(generated_random_text.split()))\n",
    "    \n",
    "    if 10 <= len(generated_random_text.split()) <= 50:\n",
    "        lengths_of_phrases_to_score.append(len(generated_random_text.split()))\n",
    "        \n",
    "        corrected_result = correct_grammar(generated_random_text)\n",
    "\n",
    "        predictions = [generated_random_text]\n",
    "        references = [[corrected_result]]\n",
    "\n",
    "        results_bleu = bleu.compute(predictions=predictions, references=references)\n",
    "        bleu_score = results_bleu['bleu']\n",
    "        bleu_scores.append(bleu_score)\n",
    "\n",
    "        results_rouge = rouge.compute(predictions=predictions, references=references)\n",
    "        rougeL_score = results_rouge['rougeL']\n",
    "        rougeL_scores.append(rougeL_score)\n",
    "\n",
    "        # to produce some examples we print 100 phrases with relative corrections\n",
    "        if to_see < 20:\n",
    "            to_see += 1\n",
    "            print(generated_random_text)\n",
    "            print(corrected_result)\n",
    "            print(\"BLEU is \", bleu_score)\n",
    "            print(\"ROUGE is \", rougeL_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081bddf8-b027-434a-a2dd-42de7ebc87aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the generated phrase length\n",
    "\n",
    "length_counts = Counter(lengths_of_phrases)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(length_counts.keys(), length_counts.values(), color='skyblue')\n",
    "plt.xlabel('Sentence Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Frequency of Generated Sentence Lengths')\n",
    "plt.xticks(list(length_counts.keys()))\n",
    "plt.grid(axis='y')\n",
    "plt.yticks(range(0, max(length_counts.values()) + 1))\n",
    "\n",
    "plt.savefig('lengths.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad469a2d-8f35-4982-b758-f38e39013600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting BLEU and ROUGE\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(lengths_of_phrases_to_score, bleu_scores, color='blue', label='BLEU Score')\n",
    "plt.scatter(lengths_of_phrases_to_score, rougeL_scores, color='red', label='ROUGE-L Score')\n",
    "\n",
    "plt.xlabel('Phrase Length')\n",
    "plt.ylabel('Score')\n",
    "plt.title('BLEU and ROUGE-L Scores')\n",
    "plt.ylim(0, 1.1)  # Scores are between 0 and 1\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig('scores.png', format='png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71661b0-11cc-44c0-93da-2787b3cb0677",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_bleu_score = np.mean(bleu_scores)\n",
    "print(\"Mean BLEU Score:\", mean_bleu_score)\n",
    "\n",
    "mean_rouge_score = np.mean(rougeL_scores)\n",
    "print(\"Mean ROUGE Score:\", mean_rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ce7b4b-1773-4364-8f6c-cd547dc4f50d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
